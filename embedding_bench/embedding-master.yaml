models:
  bge-m3:
    hf-model: BAAI/bge-m3
  e5basev2:
    hf-model: intfloat/e5-base-v2
  nv-embed-v2:
    hf-model: nvidia/NV-Embed-v2
  qwen3-embedding8b:
    hf-model: Qwen/Qwen3-Embedding-8B
  bgelarge-env15:
    hf-model: BAAI/bge-large-en-v1.5

sweep:
  chunk-sizes: [256, 512]
  batch-sizes: [1, 4, 16, 64, 128, 256]
  concurrencies: [1, 4, 16, 64]
